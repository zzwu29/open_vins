\hypertarget{classov__core_1_1TrackKLT}{}\section{ov\+\_\+core\+:\+:Track\+K\+LT Class Reference}
\label{classov__core_1_1TrackKLT}\index{ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}}


K\+LT tracking of features.  




{\ttfamily \#include $<$Track\+K\+L\+T.\+h$>$}

\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classov__core_1_1TrackKLT_acb59382fb0893c546e612fa20ca0672b}{Track\+K\+LT} (std\+::unordered\+\_\+map$<$ size\+\_\+t, std\+::shared\+\_\+ptr$<$ \hyperlink{classov__core_1_1CamBase}{Cam\+Base} $>$$>$ cameras, int numfeats, int numaruco, bool stereo, \hyperlink{classov__core_1_1TrackBase_aa4b34a5dce99b59522d57bf9278c9a1a}{Histogram\+Method} histmethod, int fast\+\_\+threshold, int gridx, int gridy, int minpxdist)
\begin{DoxyCompactList}\small\item\em Public constructor with configuration variables. \end{DoxyCompactList}\item 
void \hyperlink{classov__core_1_1TrackKLT_a8cb9c3595fbbddc9a563137cd06b07cf}{feed\+\_\+new\+\_\+camera} (const \hyperlink{structov__core_1_1CameraData}{Camera\+Data} \&message) override
\begin{DoxyCompactList}\small\item\em Process a new image. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
void \hyperlink{classov__core_1_1TrackKLT_a74d790b70b686f8f4a9788ef765ab3b1}{feed\+\_\+monocular} (const \hyperlink{structov__core_1_1CameraData}{Camera\+Data} \&message, size\+\_\+t msg\+\_\+id)
\begin{DoxyCompactList}\small\item\em Process a new monocular image. \end{DoxyCompactList}\item 
void \hyperlink{classov__core_1_1TrackKLT_a7e0f2b1990992ed7dbd916732dd9d7a9}{feed\+\_\+stereo} (const \hyperlink{structov__core_1_1CameraData}{Camera\+Data} \&message, size\+\_\+t msg\+\_\+id\+\_\+left, size\+\_\+t msg\+\_\+id\+\_\+right)
\begin{DoxyCompactList}\small\item\em Process new stereo pair of images. \end{DoxyCompactList}\item 
void \hyperlink{classov__core_1_1TrackKLT_a8443c645bf05d2ec7e5e14ae44150bcd}{perform\+\_\+detection\+\_\+monocular} (const std\+::vector$<$ cv\+::\+Mat $>$ \&img0pyr, const cv\+::\+Mat \&mask0, std\+::vector$<$ cv\+::\+Key\+Point $>$ \&pts0, std\+::vector$<$ size\+\_\+t $>$ \&ids0)
\begin{DoxyCompactList}\small\item\em Detects new features in the current image. \end{DoxyCompactList}\item 
void \hyperlink{classov__core_1_1TrackKLT_a5c88ad139cd0a0e6633ec604fdee5a86}{perform\+\_\+detection\+\_\+stereo} (const std\+::vector$<$ cv\+::\+Mat $>$ \&img0pyr, const std\+::vector$<$ cv\+::\+Mat $>$ \&img1pyr, const cv\+::\+Mat \&mask0, const cv\+::\+Mat \&mask1, size\+\_\+t cam\+\_\+id\+\_\+left, size\+\_\+t cam\+\_\+id\+\_\+right, std\+::vector$<$ cv\+::\+Key\+Point $>$ \&pts0, std\+::vector$<$ cv\+::\+Key\+Point $>$ \&pts1, std\+::vector$<$ size\+\_\+t $>$ \&ids0, std\+::vector$<$ size\+\_\+t $>$ \&ids1)
\begin{DoxyCompactList}\small\item\em Detects new features in the current stereo pair. \end{DoxyCompactList}\item 
void \hyperlink{classov__core_1_1TrackKLT_a7747a5ceca5c530350cf0c745a33bfe5}{perform\+\_\+matching} (const std\+::vector$<$ cv\+::\+Mat $>$ \&img0pyr, const std\+::vector$<$ cv\+::\+Mat $>$ \&img1pyr, std\+::vector$<$ cv\+::\+Key\+Point $>$ \&pts0, std\+::vector$<$ cv\+::\+Key\+Point $>$ \&pts1, size\+\_\+t id0, size\+\_\+t id1, std\+::vector$<$ uchar $>$ \&mask\+\_\+out)
\begin{DoxyCompactList}\small\item\em K\+LT track between two images, and do R\+A\+N\+S\+AC afterwards. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classov__core_1_1TrackKLT_ab66cf20d8dbd8140c5dddc3d584456d5}\label{classov__core_1_1TrackKLT_ab66cf20d8dbd8140c5dddc3d584456d5}} 
int {\bfseries threshold}
\item 
\mbox{\Hypertarget{classov__core_1_1TrackKLT_afecb0e0e193ad6700b1d03dbdaaf2ec8}\label{classov__core_1_1TrackKLT_afecb0e0e193ad6700b1d03dbdaaf2ec8}} 
int {\bfseries grid\+\_\+x}
\item 
\mbox{\Hypertarget{classov__core_1_1TrackKLT_ad41e009a38f832b55b833ad17e094b20}\label{classov__core_1_1TrackKLT_ad41e009a38f832b55b833ad17e094b20}} 
int {\bfseries grid\+\_\+y}
\item 
\mbox{\Hypertarget{classov__core_1_1TrackKLT_afcbe4f18535bc61a978eda8c9e55a724}\label{classov__core_1_1TrackKLT_afcbe4f18535bc61a978eda8c9e55a724}} 
int {\bfseries min\+\_\+px\+\_\+dist}
\item 
\mbox{\Hypertarget{classov__core_1_1TrackKLT_a66578875c6e0313f25e53c1de196e9cc}\label{classov__core_1_1TrackKLT_a66578875c6e0313f25e53c1de196e9cc}} 
int {\bfseries pyr\+\_\+levels} = 5
\item 
\mbox{\Hypertarget{classov__core_1_1TrackKLT_ab345d0732346d1f2af5c4a90cd6d24db}\label{classov__core_1_1TrackKLT_ab345d0732346d1f2af5c4a90cd6d24db}} 
cv\+::\+Size {\bfseries win\+\_\+size} = cv\+::\+Size(15, 15)
\item 
\mbox{\Hypertarget{classov__core_1_1TrackKLT_a0ab430fba27de7331ea06b153db82826}\label{classov__core_1_1TrackKLT_a0ab430fba27de7331ea06b153db82826}} 
std\+::map$<$ size\+\_\+t, std\+::vector$<$ cv\+::\+Mat $>$ $>$ {\bfseries img\+\_\+pyramid\+\_\+last}
\item 
\mbox{\Hypertarget{classov__core_1_1TrackKLT_a5240e79f3bd76eae568a5115b9c5e94f}\label{classov__core_1_1TrackKLT_a5240e79f3bd76eae568a5115b9c5e94f}} 
std\+::map$<$ size\+\_\+t, cv\+::\+Mat $>$ {\bfseries img\+\_\+curr}
\item 
\mbox{\Hypertarget{classov__core_1_1TrackKLT_a0b7ce6ff25bfb1e09652e236cccc89c7}\label{classov__core_1_1TrackKLT_a0b7ce6ff25bfb1e09652e236cccc89c7}} 
std\+::map$<$ size\+\_\+t, std\+::vector$<$ cv\+::\+Mat $>$ $>$ {\bfseries img\+\_\+pyramid\+\_\+curr}
\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
K\+LT tracking of features. 

This is the implementation of a K\+LT visual frontend for tracking sparse features. We can track either monocular cameras across time (temporally) along with stereo cameras which we also track across time (temporally) but track from left to right to find the stereo correspondence information also. This uses the \href{https://github.com/opencv/opencv/blob/master/modules/video/src/lkpyramid.cpp}{\tt calc\+Optical\+Flow\+Pyr\+LK} Open\+CV function to do the K\+LT tracking. 

\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classov__core_1_1TrackKLT_acb59382fb0893c546e612fa20ca0672b}\label{classov__core_1_1TrackKLT_acb59382fb0893c546e612fa20ca0672b}} 
\index{ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}!Track\+K\+LT@{Track\+K\+LT}}
\index{Track\+K\+LT@{Track\+K\+LT}!ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}}
\subsubsection{\texorpdfstring{Track\+K\+L\+T()}{TrackKLT()}}
{\footnotesize\ttfamily ov\+\_\+core\+::\+Track\+K\+L\+T\+::\+Track\+K\+LT (\begin{DoxyParamCaption}\item[{std\+::unordered\+\_\+map$<$ size\+\_\+t, std\+::shared\+\_\+ptr$<$ \hyperlink{classov__core_1_1CamBase}{Cam\+Base} $>$$>$}]{cameras,  }\item[{int}]{numfeats,  }\item[{int}]{numaruco,  }\item[{bool}]{stereo,  }\item[{\hyperlink{classov__core_1_1TrackBase_aa4b34a5dce99b59522d57bf9278c9a1a}{Histogram\+Method}}]{histmethod,  }\item[{int}]{fast\+\_\+threshold,  }\item[{int}]{gridx,  }\item[{int}]{gridy,  }\item[{int}]{minpxdist }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [explicit]}}



Public constructor with configuration variables. 


\begin{DoxyParams}{Parameters}
{\em cameras} & camera calibration object which has all camera intrinsics in it \\
\hline
{\em numfeats} & number of features we want want to track (i.\+e. track 200 points from frame to frame) \\
\hline
{\em numaruco} & the max id of the arucotags, so we ensure that we start our non-\/auroc features above this value \\
\hline
{\em stereo} & if we should do stereo feature tracking or binocular \\
\hline
{\em histmethod} & what type of histogram pre-\/processing should be done (histogram eq?) \\
\hline
{\em fast\+\_\+threshold} & F\+A\+ST detection threshold \\
\hline
{\em gridx} & size of grid in the x-\/direction / u-\/direction \\
\hline
{\em gridy} & size of grid in the y-\/direction / v-\/direction \\
\hline
{\em minpxdist} & features need to be at least this number pixels away from each other \\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classov__core_1_1TrackKLT_a74d790b70b686f8f4a9788ef765ab3b1}\label{classov__core_1_1TrackKLT_a74d790b70b686f8f4a9788ef765ab3b1}} 
\index{ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}!feed\+\_\+monocular@{feed\+\_\+monocular}}
\index{feed\+\_\+monocular@{feed\+\_\+monocular}!ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}}
\subsubsection{\texorpdfstring{feed\+\_\+monocular()}{feed\_monocular()}}
{\footnotesize\ttfamily void Track\+K\+L\+T\+::feed\+\_\+monocular (\begin{DoxyParamCaption}\item[{const \hyperlink{structov__core_1_1CameraData}{Camera\+Data} \&}]{message,  }\item[{size\+\_\+t}]{msg\+\_\+id }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Process a new monocular image. 


\begin{DoxyParams}{Parameters}
{\em message} & Contains our timestamp, images, and camera ids \\
\hline
{\em msg\+\_\+id} & the camera index in message data vector \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classov__core_1_1TrackKLT_a8cb9c3595fbbddc9a563137cd06b07cf}\label{classov__core_1_1TrackKLT_a8cb9c3595fbbddc9a563137cd06b07cf}} 
\index{ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}!feed\+\_\+new\+\_\+camera@{feed\+\_\+new\+\_\+camera}}
\index{feed\+\_\+new\+\_\+camera@{feed\+\_\+new\+\_\+camera}!ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}}
\subsubsection{\texorpdfstring{feed\+\_\+new\+\_\+camera()}{feed\_new\_camera()}}
{\footnotesize\ttfamily void Track\+K\+L\+T\+::feed\+\_\+new\+\_\+camera (\begin{DoxyParamCaption}\item[{const \hyperlink{structov__core_1_1CameraData}{Camera\+Data} \&}]{message }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [override]}, {\ttfamily [virtual]}}



Process a new image. 


\begin{DoxyParams}{Parameters}
{\em message} & Contains our timestamp, images, and camera ids \\
\hline
\end{DoxyParams}


Implements \hyperlink{classov__core_1_1TrackBase_a18f208f4047e9a1955406806ba68a8c1}{ov\+\_\+core\+::\+Track\+Base}.

\mbox{\Hypertarget{classov__core_1_1TrackKLT_a7e0f2b1990992ed7dbd916732dd9d7a9}\label{classov__core_1_1TrackKLT_a7e0f2b1990992ed7dbd916732dd9d7a9}} 
\index{ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}!feed\+\_\+stereo@{feed\+\_\+stereo}}
\index{feed\+\_\+stereo@{feed\+\_\+stereo}!ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}}
\subsubsection{\texorpdfstring{feed\+\_\+stereo()}{feed\_stereo()}}
{\footnotesize\ttfamily void Track\+K\+L\+T\+::feed\+\_\+stereo (\begin{DoxyParamCaption}\item[{const \hyperlink{structov__core_1_1CameraData}{Camera\+Data} \&}]{message,  }\item[{size\+\_\+t}]{msg\+\_\+id\+\_\+left,  }\item[{size\+\_\+t}]{msg\+\_\+id\+\_\+right }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Process new stereo pair of images. 


\begin{DoxyParams}{Parameters}
{\em message} & Contains our timestamp, images, and camera ids \\
\hline
{\em msg\+\_\+id\+\_\+left} & first image index in message data vector \\
\hline
{\em msg\+\_\+id\+\_\+right} & second image index in message data vector \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classov__core_1_1TrackKLT_a8443c645bf05d2ec7e5e14ae44150bcd}\label{classov__core_1_1TrackKLT_a8443c645bf05d2ec7e5e14ae44150bcd}} 
\index{ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}!perform\+\_\+detection\+\_\+monocular@{perform\+\_\+detection\+\_\+monocular}}
\index{perform\+\_\+detection\+\_\+monocular@{perform\+\_\+detection\+\_\+monocular}!ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}}
\subsubsection{\texorpdfstring{perform\+\_\+detection\+\_\+monocular()}{perform\_detection\_monocular()}}
{\footnotesize\ttfamily void Track\+K\+L\+T\+::perform\+\_\+detection\+\_\+monocular (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ cv\+::\+Mat $>$ \&}]{img0pyr,  }\item[{const cv\+::\+Mat \&}]{mask0,  }\item[{std\+::vector$<$ cv\+::\+Key\+Point $>$ \&}]{pts0,  }\item[{std\+::vector$<$ size\+\_\+t $>$ \&}]{ids0 }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Detects new features in the current image. 


\begin{DoxyParams}{Parameters}
{\em img0pyr} & image we will detect features on (first level of pyramid) \\
\hline
{\em mask0} & mask which has what R\+OI we do not want features in \\
\hline
{\em pts0} & vector of currently extracted keypoints in this image \\
\hline
{\em ids0} & vector of feature ids for each currently extracted keypoint\\
\hline
\end{DoxyParams}
Given an image and its currently extracted features, this will try to add new features if needed. Will try to always have the \char`\"{}max\+\_\+features\char`\"{} being tracked through K\+LT at each timestep. Passed images should already be grayscaled. \mbox{\Hypertarget{classov__core_1_1TrackKLT_a5c88ad139cd0a0e6633ec604fdee5a86}\label{classov__core_1_1TrackKLT_a5c88ad139cd0a0e6633ec604fdee5a86}} 
\index{ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}!perform\+\_\+detection\+\_\+stereo@{perform\+\_\+detection\+\_\+stereo}}
\index{perform\+\_\+detection\+\_\+stereo@{perform\+\_\+detection\+\_\+stereo}!ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}}
\subsubsection{\texorpdfstring{perform\+\_\+detection\+\_\+stereo()}{perform\_detection\_stereo()}}
{\footnotesize\ttfamily void Track\+K\+L\+T\+::perform\+\_\+detection\+\_\+stereo (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ cv\+::\+Mat $>$ \&}]{img0pyr,  }\item[{const std\+::vector$<$ cv\+::\+Mat $>$ \&}]{img1pyr,  }\item[{const cv\+::\+Mat \&}]{mask0,  }\item[{const cv\+::\+Mat \&}]{mask1,  }\item[{size\+\_\+t}]{cam\+\_\+id\+\_\+left,  }\item[{size\+\_\+t}]{cam\+\_\+id\+\_\+right,  }\item[{std\+::vector$<$ cv\+::\+Key\+Point $>$ \&}]{pts0,  }\item[{std\+::vector$<$ cv\+::\+Key\+Point $>$ \&}]{pts1,  }\item[{std\+::vector$<$ size\+\_\+t $>$ \&}]{ids0,  }\item[{std\+::vector$<$ size\+\_\+t $>$ \&}]{ids1 }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Detects new features in the current stereo pair. 


\begin{DoxyParams}{Parameters}
{\em img0pyr} & left image we will detect features on (first level of pyramid) \\
\hline
{\em img1pyr} & right image we will detect features on (first level of pyramid) \\
\hline
{\em mask0} & mask which has what R\+OI we do not want features in \\
\hline
{\em mask1} & mask which has what R\+OI we do not want features in \\
\hline
{\em cam\+\_\+id\+\_\+left} & first camera sensor id \\
\hline
{\em cam\+\_\+id\+\_\+right} & second camera sensor id \\
\hline
{\em pts0} & left vector of currently extracted keypoints \\
\hline
{\em pts1} & right vector of currently extracted keypoints \\
\hline
{\em ids0} & left vector of feature ids for each currently extracted keypoint \\
\hline
{\em ids1} & right vector of feature ids for each currently extracted keypoint\\
\hline
\end{DoxyParams}
This does the same logic as the \hyperlink{classov__core_1_1TrackKLT_a8443c645bf05d2ec7e5e14ae44150bcd}{perform\+\_\+detection\+\_\+monocular()} function, but we also enforce stereo contraints. So we detect features in the left image, and then K\+LT track them onto the right image. If we have valid tracks, then we have both the keypoint on the left and its matching point in the right image. Will try to always have the \char`\"{}max\+\_\+features\char`\"{} being tracked through K\+LT at each timestep. \mbox{\Hypertarget{classov__core_1_1TrackKLT_a7747a5ceca5c530350cf0c745a33bfe5}\label{classov__core_1_1TrackKLT_a7747a5ceca5c530350cf0c745a33bfe5}} 
\index{ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}!perform\+\_\+matching@{perform\+\_\+matching}}
\index{perform\+\_\+matching@{perform\+\_\+matching}!ov\+\_\+core\+::\+Track\+K\+LT@{ov\+\_\+core\+::\+Track\+K\+LT}}
\subsubsection{\texorpdfstring{perform\+\_\+matching()}{perform\_matching()}}
{\footnotesize\ttfamily void Track\+K\+L\+T\+::perform\+\_\+matching (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ cv\+::\+Mat $>$ \&}]{img0pyr,  }\item[{const std\+::vector$<$ cv\+::\+Mat $>$ \&}]{img1pyr,  }\item[{std\+::vector$<$ cv\+::\+Key\+Point $>$ \&}]{pts0,  }\item[{std\+::vector$<$ cv\+::\+Key\+Point $>$ \&}]{pts1,  }\item[{size\+\_\+t}]{id0,  }\item[{size\+\_\+t}]{id1,  }\item[{std\+::vector$<$ uchar $>$ \&}]{mask\+\_\+out }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



K\+LT track between two images, and do R\+A\+N\+S\+AC afterwards. 


\begin{DoxyParams}{Parameters}
{\em img0pyr} & starting image pyramid \\
\hline
{\em img1pyr} & image pyramid we want to track too \\
\hline
{\em pts0} & starting points \\
\hline
{\em pts1} & points we have tracked \\
\hline
{\em id0} & id of the first camera \\
\hline
{\em id1} & id of the second camera \\
\hline
{\em mask\+\_\+out} & what points had valid tracks\\
\hline
\end{DoxyParams}
This will track features from the first image into the second image. The two point vectors will be of equal size, but the mask\+\_\+out variable will specify which points are good or bad. If the second vector is non-\/empty, it will be used as an initial guess of where the keypoints are in the second image. 