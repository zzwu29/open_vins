<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>OpenVINS: Camera Measurement Update</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">OpenVINS
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="update.html">Measurement Update Derivations</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Camera Measurement Update </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#model">Perspective Projection (Bearing) Measurement Model</a><ul><li class="level2"><a href="#model-table">Measurement Function Overview</a></li>
<li class="level2"><a href="#model-deriv">Jacobian Computation</a></li>
</ul>
</li>
<li class="level1"><a href="#distortion">Distortion Function</a><ul><li class="level2"><a href="#distortion-radtan">Radial model</a></li>
<li class="level2"><a href="#distortion-equi">Fisheye model</a></li>
</ul>
</li>
<li class="level1"><a href="#projection">Perspective Projection Function</a></li>
<li class="level1"><a href="#relative">Euclidean Transformation</a></li>
<li class="level1"><a href="#feat-rep">Point Feature Representations</a><ul><li class="level2"><a href="#feat-rep-global-xyz">Global XYZ</a></li>
<li class="level2"><a href="#feat-rep-global-inv">Global Inverse Depth</a></li>
<li class="level2"><a href="#feat-rep-global-inv2">Global Inverse Depth (MSCKF VERSION)</a></li>
<li class="level2"><a href="#feat-rep-anchor-xyz">Anchored XYZ</a></li>
<li class="level2"><a href="#feat-rep-anchor-inv">Anchored Inverse Depth</a></li>
<li class="level2"><a href="#feat-rep-anchor-inv2">Anchored Inverse Depth (MSCKF Version)</a></li>
<li class="level2"><a href="#feat-rep-anchor-inv3">Anchored Inverse Depth (MSCKF Single Depth Version)</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="model"></a>
Perspective Projection (Bearing) Measurement Model</h1>
<p>Consider a 3D feature is detected from the camera image at time <img class="formulaInl" alt="$k$" src="form_9.png"/>, whose <img class="formulaInl" alt="$uv$" src="form_168.png"/> measurement (i.e., the corresponding pixel coordinates) on the image plane is given by:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \mathbf{z}_{m,k} &amp;= \mathbf h(\mathbf x_k) + \mathbf n_k \\ &amp;= \mathbf h_d(\mathbf{z}_{n,k}, ~\boldsymbol\zeta) + \mathbf{n}_k \\ &amp;= \mathbf h_d(\mathbf h_p({}^{C_k}\mathbf{p}_f), ~\boldsymbol\zeta) + \mathbf{n}_k \\ &amp;= \mathbf h_d(\mathbf h_p(\mathbf h_t({}^{G}\mathbf{p}_f,~{}^{C_k}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_k})), ~\boldsymbol\zeta) + \mathbf{n}_k \\ &amp;= \mathbf h_d(\mathbf h_p(\mathbf h_t(\mathbf h_r(\boldsymbol\lambda,\cdots),~{}^{C_k}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_k})), ~\boldsymbol\zeta) + \mathbf{n}_k \end{align*}" src="form_169.png"/>
</p>
<p>where <img class="formulaInl" alt="$\mathbf n_k$" src="form_170.png"/> is the measurement noise and typically assumed to be zero-mean white Gaussian; <img class="formulaInl" alt="$\mathbf z_{n,k}$" src="form_171.png"/> is the normalized undistorted uv measurement; <img class="formulaInl" alt="$\boldsymbol\zeta$" src="form_172.png"/> is the camera intrinsic parameters such as focal length and distortion parameters; <img class="formulaInl" alt="${}^{C_k}\mathbf{p}_f$" src="form_173.png"/> is the feature position in the current camera frame <img class="formulaInl" alt="$\{C_k\}$" src="form_174.png"/>; <img class="formulaInl" alt="${}^{G}\mathbf{p}_f$" src="form_175.png"/> is the feature position in the global frame <img class="formulaInl" alt="$\{G\}$" src="form_57.png"/>; <img class="formulaInl" alt="$\{ {}^{C_k}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_k} \}$" src="form_176.png"/> denotes the current camera pose (position and orientation) in the global frame (or camera extrinsics); and <img class="formulaInl" alt="$\boldsymbol\lambda$" src="form_177.png"/> is the feature's parameters of different representations (other than position) such as simply a xyz position or an inverse depth with bearing.</p>
<p>In the above expression, we decompose the measurement function into multiple concatenated functions corresponding to different operations, which map the states into the raw uv measurement on the image plane. It should be noted that as we will perform intrinsic calibration along with extrinsic with different feature representations, the above camera measurement model is general. The high-level description of each function is given in the next section.</p>
<h2><a class="anchor" id="model-table"></a>
Measurement Function Overview</h2>
<table class="doxtable">
<tr>
<th>Function </th><th>Description  </th></tr>
<tr>
<td><img class="formulaInl" alt="$\mathbf{z}_k = \mathbf h_d (\mathbf{z}_{n,k}, ~\boldsymbol\zeta)$" src="form_178.png"/> </td><td>The distortion function that takes normalized coordinates and maps it into distorted uv coordinates </td></tr>
<tr>
<td><img class="formulaInl" alt="$\mathbf{z}_{n,k}= \mathbf h_p({}^{C_k}\mathbf{p}_f)$" src="form_179.png"/></td><td>The projection function that takes a 3D point in the image and converts it into the normalized uv coordinates </td></tr>
<tr>
<td><img class="formulaInl" alt="${}^{C_k}\mathbf{p}_f=\mathbf h_t({}^{G}\mathbf{p}_f,~{}^{C_k}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_k})$" src="form_180.png"/> </td><td>Transforming a feature's position in the global frame into the current camera frame </td></tr>
<tr>
<td><img class="formulaInl" alt="${}^{G}\mathbf{p}_f= \mathbf h_r(\boldsymbol\lambda,\cdots)$" src="form_181.png"/> </td><td>Converting from a feature representation to a 3D feature in the global frame </td></tr>
</table>
<h2><a class="anchor" id="model-deriv"></a>
Jacobian Computation</h2>
<p>Given the above nested functions, we can leverage the chainrule to find the total state Jacobian. Since our feature representation function <img class="formulaInl" alt="$\mathbf h_r(\cdots)$" src="form_182.png"/> might also depend on the state, i.e. an anchoring pose, we need to carefully consider its additional derivatives. Consider the following example of our measurement in respect to a state <img class="formulaInl" alt="$ \mathbf{x} $" src="form_183.png"/> Jacobian:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf{z}_k}{\partial \mathbf{x}} = \frac{\partial \mathbf h_d (\cdot) }{\partial \mathbf{z}_{n,k}} \frac{\partial \mathbf h_p (\cdot) }{\partial {}^{C_k}\mathbf{p}_f} \frac{\partial \mathbf h_t (\cdot) }{\partial \mathbf{x}} + \frac{\partial \mathbf h_d (\cdot) }{\partial \mathbf{z}_{n,k}} \frac{\partial \mathbf h_p (\cdot) }{\partial {}^{C_k}\mathbf{p}_f} \frac{\partial \mathbf h_t (\cdot) }{\partial {}^{G}\mathbf{p}_f} \frac{\partial \mathbf h_r (\cdot) }{\partial \mathbf{x}} \end{align*}" src="form_184.png"/>
</p>
<p>In the global feature representations, see <a class="el" href="update-feat.html#feat-rep">Point Feature Representations</a> section, the second term will be zero while for the anchored representations it will need to be computed.</p>
<h1><a class="anchor" id="distortion"></a>
Distortion Function</h1>
<h2><a class="anchor" id="distortion-radtan"></a>
Radial model</h2>
<p>To calibrate camera intrinsics, we need to know how to map our normalized coordinates into the raw pixel coordinates on the image plane. We first employ the radial distortion as in <a href="https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#details">OpenCV model</a>:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \begin{bmatrix} u \\ v \end{bmatrix}:= \mathbf{z}_k &amp;= \mathbf h_d(\mathbf{z}_{n,k}, ~\boldsymbol\zeta) = \begin{bmatrix} f_x * x + c_x \\ f_y * y + c_y \end{bmatrix}\\[1em] \empty {\rm where}~~ x &amp;= x_n (1 + k_1 r^2 + k_2 r^4) + 2 p_1 x_n y_n + p_2(r^2 + 2 x_n^2) \\\ y &amp;= y_n (1 + k_1 r^2 + k_2 r^4) + p_1 (r^2 + 2 y_n^2) + 2 p_2 x_n y_n \\[1em] r^2 &amp;= x_n^2 + y_n^2 \end{align*}" src="form_185.png"/>
</p>
<p>where <img class="formulaInl" alt="$ \mathbf{z}_{n,k} = [ x_n ~ y_n ]^\top$" src="form_186.png"/> are the normalized coordinates of the 3D feature and u and v are the distorted image coordinates on the image plane. The following distortion and camera intrinsic (focal length and image center) parameters are involved in the above distortion model, which can be estimated online:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \boldsymbol\zeta = \begin{bmatrix} f_x &amp; f_y &amp; c_x &amp; c_y &amp; k_1 &amp; k_2 &amp; p_1 &amp; p_2 \end{bmatrix}^\top \end{align*}" src="form_187.png"/>
</p>
<p>Note that we do not estimate the higher order (i.e., higher than fourth order) terms as in most offline calibration methods such as <a href="https://github.com/ethz-asl/kalibr">Kalibr</a>. To estimate these intrinsic parameters (including the distortation parameters), the following Jacobian for these parameters is needed:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf h_d(\cdot)}{\partial \boldsymbol\zeta} = \begin{bmatrix} x &amp; 0 &amp; 1 &amp; 0 &amp; f_x*(x_nr^2) &amp; f_x*(x_nr^4) &amp; f_x*(2x_ny_n) &amp; f_x*(r^2+2x_n^2) \\[5pt] 0 &amp; y &amp; 0 &amp; 1 &amp; f_y*(y_nr^2) &amp; f_y*(y_nr^4) &amp; f_y*(r^2+2y_n^2) &amp; f_y*(2x_ny_n) \end{bmatrix} \end{align*}" src="form_188.png"/>
</p>
<p>Similarly, the Jacobian with respect to the normalized coordinates can be obtained as follows:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf h_d (\cdot)}{\partial \mathbf{z}_{n,k}} = \begin{bmatrix} f_x*((1+k_1r^2+k_2r^4)+(2k_1x_n^2+4k_2x_n^2(x_n^2+y_n^2))+2p_1y_n+(2p_2x_n+4p_2x_n)) &amp; f_x*(2k_1x_ny_n+4k_2x_ny_n(x_n^2+y_n^2)+2p_1x_n+2p_2y_n) \\ f_y*(2k_1x_ny_n+4k_2x_ny_n(x_n^2+y_n^2)+2p_1x_n+2p_2y_n) &amp; f_y*((1+k_1r^2+k_2r^4)+(2k_1y_n^2+4k_2y_n^2(x_n^2+y_n^2))+(2p_1y_n+4p_1y_n)+2p_2x_n) \end{bmatrix} \end{align*}" src="form_189.png"/>
</p>
<h2><a class="anchor" id="distortion-equi"></a>
Fisheye model</h2>
<p>As fisheye or wide-angle lenses are widely used in practice, we here provide mathematical derivations of such distortion model as in <a href="https://docs.opencv.org/3.4/db/d58/group__calib3d__fisheye.html#details">OpenCV fisheye</a>.</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \begin{bmatrix} u \\ v \end{bmatrix}:= \mathbf{z}_k &amp;= \mathbf h_d(\mathbf{z}_{n,k}, ~\boldsymbol\zeta) = \begin{bmatrix} f_x * x + c_x \\ f_y * y + c_y \end{bmatrix}\\[1em] \empty {\rm where}~~ x &amp;= \frac{x_n}{r} * \theta_d \\ y &amp;= \frac{y_n}{r} * \theta_d \\ \theta_d &amp;= \theta (1 + k_1 \theta^2 + k_2 \theta^4 + k_3 \theta^6 + k_4 \theta^8) \\ \quad r^2 &amp;= x_n^2 + y_n^2 \\ \theta &amp;= atan(r) \end{align*}" src="form_190.png"/>
</p>
<p>where <img class="formulaInl" alt="$ \mathbf{z}_{n,k} = [ x_n ~ y_n ]^\top$" src="form_186.png"/> are the normalized coordinates of the 3D feature and u and v are the distorted image coordinates on the image plane. Clearly, the following distortion intrinsic parameters are used in the above model:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \boldsymbol\zeta = \begin{bmatrix} f_x &amp; f_y &amp; c_x &amp; c_y &amp; k_1 &amp; k_2 &amp; k_3 &amp; k_4 \end{bmatrix}^\top \end{align*}" src="form_191.png"/>
</p>
<p>In analogy to the previous radial distortion case, the following Jacobian for these parameters is needed for intrinsic calibration:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf h_d (\cdot)}{\partial \boldsymbol\zeta} = \begin{bmatrix} x_n &amp; 0 &amp; 1 &amp; 0 &amp; f_x*(\frac{x_n}{r}\theta^3) &amp; f_x*(\frac{x_n}{r}\theta^5) &amp; f_x*(\frac{x_n}{r}\theta^7) &amp; f_x*(\frac{x_n}{r}\theta^9) \\[5pt] 0 &amp; y_n &amp; 0 &amp; 1 &amp; f_y*(\frac{y_n}{r}\theta^3) &amp; f_y*(\frac{y_n}{r}\theta^5) &amp; f_y*(\frac{y_n}{r}\theta^7) &amp; f_y*(\frac{y_n}{r}\theta^9) \end{bmatrix} \end{align*}" src="form_192.png"/>
</p>
<p>Similarly, with the chain rule of differentiation, we can compute the following Jacobian with respect to the normalized coordinates:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf h_d(\cdot)}{\partial \mathbf{z}_{n,k}} &amp;= \frac{\partial uv}{\partial xy}\frac{\partial xy}{\partial x_ny_n}+ \frac{\partial uv}{\partial xy}\frac{\partial xy}{\partial r}\frac{\partial r}{\partial x_ny_n}+ \frac{\partial uv}{\partial xy}\frac{\partial xy}{\partial \theta_d}\frac{\partial \theta_d}{\partial \theta}\frac{\partial \theta}{\partial r}\frac{\partial r}{\partial x_ny_n} \\[1em] \empty {\rm where}~~~~ \frac{\partial uv}{\partial xy} &amp;= \begin{bmatrix} f_x &amp; 0 \\ 0 &amp; f_y \end{bmatrix} \\ \empty \frac{\partial xy}{\partial x_ny_n} &amp;= \begin{bmatrix} \theta_d/r &amp; 0 \\ 0 &amp; \theta_d/r \end{bmatrix} \\ \empty \frac{\partial xy}{\partial r} &amp;= \begin{bmatrix} -\frac{x_n}{r^2}\theta_d \\ -\frac{y_n}{r^2}\theta_d \end{bmatrix} \\ \empty \frac{\partial r}{\partial x_ny_n} &amp;= \begin{bmatrix} \frac{x_n}{r} &amp; \frac{y_n}{r} \end{bmatrix} \\ \empty \frac{\partial xy}{\partial \theta_d} &amp;= \begin{bmatrix} \frac{x_n}{r} \\ \frac{y_n}{r} \end{bmatrix} \\ \empty \frac{\partial \theta_d}{\partial \theta} &amp;= \begin{bmatrix} 1 + 3k_1 \theta^2 + 5k_2 \theta^4 + 7k_3 \theta^6 + 9k_4 \theta^8\end{bmatrix} \\ \empty \frac{\partial \theta}{\partial r} &amp;= \begin{bmatrix} \frac{1}{r^2+1} \end{bmatrix} \end{align*}" src="form_193.png"/>
</p>
<h1><a class="anchor" id="projection"></a>
Perspective Projection Function</h1>
<p>The standard pinhole camera model is used to project a 3D point in the <em>camera</em> frame into the normalized image plane (with unit depth):</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \mathbf{z}_{n,k} &amp;= \mathbf h_p ({}^{C_k}\mathbf{p}_f) = \begin{bmatrix} {}^Cx/{}^Cz \\ {}^Cy/{}^Cz \end{bmatrix} \\ \text{where} \quad {}^{C_k}\mathbf{p}_f &amp;= \begin{bmatrix} {}^Cx \\ {}^Cy \\ {}^Cz \end{bmatrix} \end{align*}" src="form_194.png"/>
</p>
<p>whose Jacobian matrix is computed as follows:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf h_p (\cdot)}{\partial {}^{C_k}\mathbf{p}_f} = \begin{bmatrix} \frac{1}{{}^Cz} &amp; 0 &amp; \frac{-{}^Cx}{({}^Cz)^2} \\ 0 &amp; \frac{1}{{}^Cz} &amp; \frac{-{}^Cy}{({}^Cz)^2} \\ \end{bmatrix} \end{align*}" src="form_195.png"/>
</p>
<h1><a class="anchor" id="relative"></a>
Euclidean Transformation</h1>
<p>We employ the 6DOF rigid-body Euclidean transformation to transform the 3D feature position in the global frame <img class="formulaInl" alt="$\{G\}$" src="form_57.png"/> to the current camera frame <img class="formulaInl" alt="$\{C_k\}$" src="form_174.png"/> based on the current global camera pose:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{C_k}\mathbf{p}_f &amp;= \mathbf h_t ({}^{G}\mathbf{p}_f,~{}^{C_k}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{C_k}) = {}^{C_k}_{G}\mathbf{R}({}^{G}\mathbf{p}_f-{}^{G}\mathbf{p}_{C_k}) \end{align*}" src="form_196.png"/>
</p>
<p>Note that in visual-inertial navigation systems, we often keep the IMU, instead of camera, state in the state vector. So, we need to further transform the above geometry using the time-invariant IMU-camera extrinsic parameters <img class="formulaInl" alt="$\{ {}^{C}_{I}\mathbf{R}, ~{}^{C}\mathbf{p}_I \}$" src="form_197.png"/> as follows:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{G}\mathbf{p}_{C_k} &amp;= {}^{G}\mathbf{p}_{I_k} + {}^{G}_{I}\mathbf{R} {}^{I}\mathbf{p}_{C_k} = {}^{G}\mathbf{p}_{I_k} + {}^{G}_{I}\mathbf{R} {}^{I}\mathbf{p}_{C} \\ {}^{C_k}_{G}\mathbf{R} &amp;= {}^{C_k}_{I}\mathbf{R} {}^{I_k}_{G}\mathbf{R} = {}^{C}_{I}\mathbf{R} {}^{I_k}_{G}\mathbf{R} \end{align*}" src="form_198.png"/>
</p>
<p>Substituting these quantities into the equation of <img class="formulaInl" alt="$ {}^{C_k}\mathbf{p}_f$" src="form_199.png"/> yields:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{C_k}\mathbf{p}_f = {}^{C}_{I}\mathbf{R}{}^{I_k}_{G}\mathbf{R}({}^{G}\mathbf{p}_f-{}^{G}\mathbf{p}_{I_k}) +{}^{C}\mathbf{p}_I \end{align*}" src="form_200.png"/>
</p>
<p>We now can compute the following Jacobian with respect to the pertinent states:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf h_t (\cdot)}{\partial {}^{G}\mathbf{p}_f} &amp;= {}^{C}_{I}\mathbf{R}{}^{I_k}_{G}\mathbf{R} \\ \frac{\partial \mathbf h_t (\cdot)}{\partial {}^{I_k}_{G}\mathbf{R}} &amp;= {}^{C}_{I}\mathbf{R} \left\lfloor {}^{I_k}_{G}\mathbf{R}({}^{G}\mathbf{p}_f-{}^{G}\mathbf{p}_{I_k}) \times\right\rfloor \\ \frac{\partial \mathbf h_t (\cdot)}{\partial {}^{G}\mathbf{p}_{I_k}} &amp;= -{}^{C}_{I}\mathbf{R}{}^{I_k}_{G}\mathbf{R} \end{align*}" src="form_201.png"/>
</p>
<p>where <img class="formulaInl" alt="$\lfloor \mathbf a\times \rfloor $" src="form_202.png"/> denotes the skew symmetric matrix of a vector <img class="formulaInl" alt="$\mathbf a$" src="form_203.png"/> (see <a href="http://mars.cs.umn.edu/tr/reports/Trawny05b.pdf">Quaternion TR</a> <a class="el" href="citelist.html#CITEREF_Trawny2005TR">[22]</a>). Note also that in above expression (as well as in ensuing derivations), there is a little abuse of notation; that is, the Jacobian with respect to the rotation matrix is not the direct differentiation with respect to the 3x3 rotation matrix, instead with respect to the corresponding 3x1 rotation angle vector. Moreover, if performing online extrinsic calibration, the Jacobian with respect to the IMU-camera extrinsics is needed:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf h_t (\cdot)}{\partial {}^{C}_{I}\mathbf{R}} &amp;= \left\lfloor {}^{C}_{I}\mathbf{R}{}^{I_k}_{G}\mathbf{R}({}^{G}\mathbf{p}_f-{}^{G}\mathbf{p}_{I_k}) \times\right\rfloor \\ \frac{\partial \mathbf h_t (\cdot)}{\partial {}^{C}\mathbf{p}_I} &amp;= \mathbf{I}_{3\times 3} \end{align*}" src="form_204.png"/>
</p>
<h1><a class="anchor" id="feat-rep"></a>
Point Feature Representations</h1>
<p>There are two main parameterizations of a 3D point feature: 3D position (xyz) and inverse depth with bearing. Both of these can either be represented in the global frame or in an anchor frame of reference which adds a dependency on having an "anchor" pose where the feature is observed. To allow for a unified treatment of different feature parameterizations <img class="formulaInl" alt="$\boldsymbol \lambda$" src="form_205.png"/> in our codebase, we derive in detail the generic function <img class="formulaInl" alt="${}^{G}\mathbf{p}_f=\mathbf f (\cdot)$" src="form_206.png"/> that maps different representations into global position.</p>
<h2><a class="anchor" id="feat-rep-global-xyz"></a>
Global XYZ</h2>
<p>As the canonical parameterization, the global position of a 3D point feature is simply given by its xyz coordinates in the global frame of reference:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{G}\mathbf{p}_f &amp;= \mathbf f(\boldsymbol\lambda) \\ &amp;= \begin{bmatrix} {}^Gx \\ {}^Gy \\ {}^Gz \end{bmatrix} \\ \text{where} &amp;\quad \boldsymbol\lambda = {}^{G}\mathbf{p}_f = \begin{bmatrix} {}^Gx &amp; {}^Gy &amp; {}^Gz \end{bmatrix}^\top \end{align*}" src="form_207.png"/>
</p>
<p>It is clear that the Jacobian with respect to the feature parameters is: </p><p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial \boldsymbol\lambda} &amp;= \mathbf{I}_{3\times 3} \end{align*}" src="form_208.png"/>
</p>
<h2><a class="anchor" id="feat-rep-global-inv"></a>
Global Inverse Depth</h2>
<p>The global inverse-depth representation of a 3D point feature is given by (akin to spherical coordinates):</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{G}\mathbf{p}_f &amp;= \mathbf f(\boldsymbol\lambda) \\ &amp;= \frac{1}{\rho}\begin{bmatrix} \cos(\theta)\sin(\phi) \\ \sin(\theta)\sin(\phi) \\ \cos(\phi) \end{bmatrix} \\ \text{where} &amp;\quad \boldsymbol\lambda = \begin{bmatrix} \theta &amp; \phi &amp; \rho \end{bmatrix}^\top \end{align*}" src="form_209.png"/>
</p>
<p>The Jacobian with respect to the feature parameters can be computed as: </p><p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial \boldsymbol\lambda} &amp;= \begin{bmatrix} -\frac{1}{\rho}\sin(\theta)\sin(\phi) &amp; \frac{1}{\rho}\cos(\theta)\cos(\phi) &amp; -\frac{1}{\rho^2}\cos(\theta)\sin(\phi) \\ \frac{1}{\rho}\cos(\theta)\sin(\phi) &amp; \frac{1}{\rho}\sin(\theta)\cos(\phi) &amp; -\frac{1}{\rho^2}\sin(\theta)\sin(\phi) \\ 0 &amp; -\frac{1}{\rho}\sin(\phi) &amp; -\frac{1}{\rho^2}\cos(\phi) \end{bmatrix} \end{align*}" src="form_210.png"/>
</p>
<h2><a class="anchor" id="feat-rep-global-inv2"></a>
Global Inverse Depth (MSCKF VERSION)</h2>
<p>Note that as this representation has a singularity when the z-distance goes to zero, it is not recommended to use in practice. Instead, one should use the <a class="el" href="update-feat.html#feat-rep-anchor-inv2">Anchored Inverse Depth (MSCKF Version)</a> representation. The anchored version doesn't have this issue if features are represented in a camera frame that they where seen from (in which features should never have a non-positive z-direction).</p>
<h2><a class="anchor" id="feat-rep-anchor-xyz"></a>
Anchored XYZ</h2>
<p>We can represent a 3D point feature in some "anchor" frame (say some IMU local frame, <img class="formulaInl" alt="$\{{}^{I_a}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{I_a}\}$" src="form_211.png"/>), which would normally be the IMU pose corresponding to the first camera frame where the feature was detected.</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{G}\mathbf{p}_f &amp;= \mathbf f(\boldsymbol\lambda,~{}^{I_a}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{I_a},~{}^{C}_{I}\mathbf{R},~{}^{C}\mathbf{p}_{I}) \\ &amp;= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top( \boldsymbol\lambda -{}^{C}\mathbf{p}_{I}) + {}^{G}\mathbf{p}_{I_a} \\ \text{where} &amp;\quad \boldsymbol\lambda = {}^{C_a}\mathbf{p}_f = \begin{bmatrix} {}^{C_a}x &amp; {}^{C_a}y &amp; {}^{C_a}z \end{bmatrix}^\top \end{align*}" src="form_212.png"/>
</p>
<p>The Jacobian with respect to the feature state is given by:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial \boldsymbol\lambda} &amp;= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \end{align*}" src="form_213.png"/>
</p>
<p>As the anchor pose is involved in this representation, its Jacobians are computed as:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial {}^{I_a}_{G}\mathbf{R}} &amp;= -{}^{I_a}_{G}\mathbf{R}^\top \left\lfloor{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\ \frac{\partial \mathbf f(\cdot)}{\partial {}^{G}\mathbf{p}_{I_a}} &amp;= \mathbf{I}_{3\times 3} \end{align*}" src="form_214.png"/>
</p>
<p>Moreover, if performing extrinsic calibration, the following Jacobians with respect to the IMU-camera extrinsics are also needed:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial {}^{C}_{I}\mathbf{R}} &amp;= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \left\lfloor({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\ \frac{\partial \mathbf f(\cdot)}{\partial {}^{C}\mathbf{p}_{I}} &amp;= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \end{align*}" src="form_215.png"/>
</p>
<h2><a class="anchor" id="feat-rep-anchor-inv"></a>
Anchored Inverse Depth</h2>
<p>In analogy to the global inverse depth case, we can employ the inverse-depth with bearing (akin to spherical coordinates) in the anchor frame, <img class="formulaInl" alt="$\{{}^{I_a}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{I_a}\}$" src="form_211.png"/>, to represent a 3D point feature:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{G}\mathbf{p}_f &amp;= \mathbf f(\boldsymbol\lambda,~{}^{I_a}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{I_a},~{}^{C}_{I}\mathbf{R},~{}^{C}\mathbf{p}_{I}) \\ &amp;= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) + {}^{G}\mathbf{p}_{I_a} \\ &amp;= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top\Bigg(\frac{1}{\rho}\begin{bmatrix} \cos(\theta)\sin(\phi) \\ \sin(\theta)\sin(\phi) \\ \cos(\phi) \end{bmatrix}-{}^{C}\mathbf{p}_{I}\Bigg) + {}^{G}\mathbf{p}_{I_a} \\ \text{where} &amp;\quad \boldsymbol\lambda = \begin{bmatrix} \theta &amp; \phi &amp; \rho \end{bmatrix}^\top \end{align*}" src="form_216.png"/>
</p>
<p>The Jacobian with respect to the feature state is given by:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial \boldsymbol\lambda} &amp;= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \begin{bmatrix} -\frac{1}{\rho}\sin(\theta)\sin(\phi) &amp; \frac{1}{\rho}\cos(\theta)\cos(\phi) &amp; -\frac{1}{\rho^2}\cos(\theta)\sin(\phi) \\ \frac{1}{\rho}\cos(\theta)\sin(\phi) &amp; \frac{1}{\rho}\sin(\theta)\cos(\phi) &amp; -\frac{1}{\rho^2}\sin(\theta)\sin(\phi) \\ 0 &amp; -\frac{1}{\rho}\sin(\phi) &amp; -\frac{1}{\rho^2}\cos(\phi) \end{bmatrix} \end{align*}" src="form_217.png"/>
</p>
<p>The Jacobians with respect to the anchor pose are:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial {}^{I_a}_{G}\mathbf{R}} &amp;= -{}^{I_a}_{G}\mathbf{R}^\top \left\lfloor{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\ \frac{\partial \mathbf f(\cdot)}{\partial {}^{G}\mathbf{p}_{I_a}} &amp;= \mathbf{I}_{3\times 3} \end{align*}" src="form_214.png"/>
</p>
<p>The Jacobians with respect to the IMU-camera extrinsics are:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial {}^{C}_{I}\mathbf{R}} &amp;= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \left\lfloor({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\ \frac{\partial \mathbf f(\cdot)}{\partial {}^{C}\mathbf{p}_{I}} &amp;= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \end{align*}" src="form_215.png"/>
</p>
<h2><a class="anchor" id="feat-rep-anchor-inv2"></a>
Anchored Inverse Depth (MSCKF Version)</h2>
<p>Note that a simpler version of inverse depth was used in the original MSCKF paper <a class="el" href="citelist.html#CITEREF_Mourikis2007ICRA">[16]</a>. This representation does not have the singularity if it is represented in a camera frame the feature was measured from.</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{G}\mathbf{p}_f &amp;= \mathbf f(\boldsymbol\lambda,~{}^{I_a}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{I_a},~{}^{C}_{I}\mathbf{R},~{}^{C}\mathbf{p}_{I}) \\ &amp;= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) + {}^{G}\mathbf{p}_{I_a} \\ &amp;= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top\Bigg(\frac{1}{\rho}\begin{bmatrix} \alpha \\ \beta \\ 1 \end{bmatrix}-{}^{C}\mathbf{p}_{I}\Bigg) + {}^{G}\mathbf{p}_{I_a} \\ \text{where} &amp;\quad \boldsymbol\lambda = \begin{bmatrix} \alpha &amp; \beta &amp; \rho \end{bmatrix}^\top \end{align*}" src="form_218.png"/>
</p>
<p>The Jacobian with respect to the feature state is:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial \boldsymbol\lambda} &amp;= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \begin{bmatrix} \frac{1}{\rho} &amp; 0 &amp; -\frac{1}{\rho^2}\alpha \\ 0 &amp; \frac{1}{\rho} &amp; -\frac{1}{\rho^2}\beta \\ 0 &amp; 0 &amp; -\frac{1}{\rho^2} \end{bmatrix} \end{align*}" src="form_219.png"/>
</p>
<p>The Jacobians with respect to the anchor state are:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial {}^{I_a}_{G}\mathbf{R}} &amp;= -{}^{I_a}_{G}\mathbf{R}^\top \left\lfloor{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\ \frac{\partial \mathbf f(\cdot)}{\partial {}^{G}\mathbf{p}_{I_a}} &amp;= \mathbf{I}_{3\times 3} \end{align*}" src="form_214.png"/>
</p>
<p>The Jacobians with respect to the IMU-camera extrinsics are:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf f(\cdot)}{\partial {}^{C}_{I}\mathbf{R}} &amp;= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \left\lfloor({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) \times\right\rfloor \\ \frac{\partial \mathbf f(\cdot)}{\partial {}^{C}\mathbf{p}_{I}} &amp;= -{}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top \end{align*}" src="form_215.png"/>
</p>
<h2><a class="anchor" id="feat-rep-anchor-inv3"></a>
Anchored Inverse Depth (MSCKF Single Depth Version)</h2>
<p>This feature representation is based on the MSCKF representation <a class="el" href="citelist.html#CITEREF_Mourikis2007ICRA">[16]</a>, and the the single depth from VINS-Mono <a class="el" href="citelist.html#CITEREF_Qin2018TRO">[19]</a>. As compared to the implementation in <a class="el" href="citelist.html#CITEREF_Qin2018TRO">[19]</a>, we are careful about how we handle treating of the bearing of the feature. During initialization we initialize a full 3D feature and then follow that by marginalize the bearing portion of it leaving the depth in the state vector. The marginalized bearing is then fixed for all future linearizations.</p>
<p>Then during update, we perform nullspace projection at every timestep to remove the feature dependence on this bearing. To do so, we need at least <em>two</em> sets of UV measurements to perform this bearing nullspace operation since we loose two dimensions of the feature in the process. We can define the feature measurement function as follows:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{G}\mathbf{p}_f &amp;= \mathbf f(\boldsymbol\lambda,~{}^{I_a}_{G}\mathbf{R},~{}^{G}\mathbf{p}_{I_a},~{}^{C}_{I}\mathbf{R},~{}^{C}\mathbf{p}_{I}) \\ &amp;= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top({}^{C_a}\mathbf{p}_f-{}^{C}\mathbf{p}_{I}) + {}^{G}\mathbf{p}_{I_a} \\ &amp;= {}^{I_a}_{G}\mathbf{R}^\top{}^{C}_{I}\mathbf{R}^\top\Big(\frac{1}{\rho}\hat{\mathbf{b}}-{}^{C}\mathbf{p}_{I}\Big) + {}^{G}\mathbf{p}_{I_a} \\ \text{where} &amp;\quad \boldsymbol\lambda = \begin{bmatrix} \rho \end{bmatrix} \end{align*}" src="form_220.png"/>
</p>
<p>In the above case we have defined a bearing <img class="formulaInl" alt="$\hat{\mathbf{b}}$" src="form_221.png"/> which is the marginalized bearing of the feature after initialization. After collecting two measurement, we can nullspace project to remove the Jacobian in respect to this bearing variable. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
