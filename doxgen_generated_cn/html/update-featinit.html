<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>OpenVINS: Feature Triangulation</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">OpenVINS
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- 制作者 Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'搜索');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','搜索');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="update.html">Measurement Update Derivations</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Feature Triangulation </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>目录</h3>
<ul><li class="level1"><a href="#featinit-linear">3D Cartesian Triangulation</a></li>
<li class="level1"><a href="#featinit-linear-1d">1D Depth Triangulation</a></li>
<li class="level1"><a href="#featinit-nonlinear">3D Inverse Non-linear Optimization</a></li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="featinit-linear"></a>
3D Cartesian Triangulation</h1>
<p>We wish to create a solvable linear system that can give us an initial guess for the 3D cartesian position of our feature. To do this, we take all the poses that the feature is seen from to be of known quantity. This feature will be triangulated in some anchor camera frame <img class="formulaInl" alt="$\{A\}$" src="form_222.png"/> which we can arbitrary pick. If the feature <img class="formulaInl" alt="$\mathbf{p}_f$" src="form_223.png"/> is observed by pose <img class="formulaInl" alt="$1\ldots m$" src="form_224.png"/>, given the anchor pose <img class="formulaInl" alt="$A$" src="form_225.png"/>, we can have the following transformation from any camera pose <img class="formulaInl" alt="$C_i, i=1\ldots m$" src="form_226.png"/>:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{C_i}\mathbf{p}_{f} &amp; = {}^{C_i}_A\mathbf{R} \left( {}^A\mathbf{p}_f - {}^A\mathbf{p}_{C_i}\right) \\ {}^A\mathbf{p}_f &amp; = {}^{C_i}_A\mathbf{R}^\top {}^{C_i}\mathbf{p}_{f} + {}^A\mathbf{p}_{C_i} \end{align*}" src="form_227.png"/>
</p>
<p>In the absents of noise, the measurement in the current frame is the bearing <img class="formulaInl" alt="${}^{C_i}\mathbf{b}$" src="form_228.png"/> and its depth <img class="formulaInl" alt="${}^{C_i}z$" src="form_229.png"/>. Thus we have the following mapping to a feature seen from the current frame:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{C_i}\mathbf{p}_f &amp; = {}^{C_i}z_{f} {}^{C_i}\mathbf{b}_{f} = {}^{C_i}z_{f} \begin{bmatrix} u_n \\ v_n \\ 1 \end{bmatrix} \end{align*}" src="form_230.png"/>
</p>
<p>We note that <img class="formulaInl" alt="$u_n$" src="form_231.png"/> and <img class="formulaInl" alt="$v_n$" src="form_232.png"/> represent the undistorted normalized image coordinates. This bearing can be warped into the the anchor frame by substituting into the above equation:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^A\mathbf{p}_f &amp; = {}^{C_i}_A\mathbf{R}^\top {}^{C_i}z_{f} {}^{C_i}\mathbf{b}_{f} + {}^A\mathbf{p}_{C_i} \\ &amp; = {}^{C_i}z_{f} {}^{A}\mathbf{b}_{C_i \rightarrow f} + {}^A\mathbf{p}_{C_i} \end{align*}" src="form_233.png"/>
</p>
<p>To remove the need to estimate the extra degree of freedom of depth <img class="formulaInl" alt="${}^{C_i}z_{f}$" src="form_234.png"/>, we define the following vectors which are orthoganal to the bearing <img class="formulaInl" alt="${}^{A}\mathbf{b}_{C_i \rightarrow f}$" src="form_235.png"/>:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{A}\mathbf{N}_i &amp;= \lfloor {}^{A}\mathbf{b}_{C_i \rightarrow f} \times\rfloor = \begin{bmatrix} 0 &amp; -{}^{A}{b}_{C_i \rightarrow f}(3) &amp; {}^{A}{b}_{C_i \rightarrow f}(2) \\ {}^{A}{b}_{C_i \rightarrow f}(3) &amp; 0 &amp; -{}^{A}{b}_{C_i \rightarrow f}(1) \\ -{}^{A}{b}_{C_i \rightarrow f}(2) &amp; {}^{A}{b}_{C_i \rightarrow f}(1) &amp; 0 \\ \end{bmatrix} \end{align*}" src="form_236.png"/>
</p>
<p>All three rows are perpendicular to the vector <img class="formulaInl" alt="${}^{A}\mathbf{b}_{C_i \rightarrow f}$" src="form_235.png"/> and thus <img class="formulaInl" alt="${}^{A}\mathbf{N}_i{}^{A}\mathbf{b}_{C_i \rightarrow f}=\mathbf{0}_3$" src="form_237.png"/>. We can then multiple the transform equation/constraint to form two equation which only relates to the unknown 3 d.o.f <img class="formulaInl" alt="${}^A\mathbf{p}_f$" src="form_238.png"/>:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{A}\mathbf{N}_i {}^A\mathbf{p}_f &amp; = {}^{A}\mathbf{N}_i {}^{C_i}z_{f} {}^{A}\mathbf{b}_{C_i \rightarrow f} + {}^{A}\mathbf{N}_i {}^A\mathbf{p}_{C_i} \\ &amp; = {}^{A}\mathbf{N}_i {}^A\mathbf{p}_{C_i} \end{align*}" src="form_239.png"/>
</p>
<p>By stacking all the measurements, we can have:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \underbrace{ \begin{bmatrix} \vdots \\ {}^{A}\mathbf{N}_i \\ \vdots \end{bmatrix} }_{\mathbf{A}} {}^A\mathbf{p}_f &amp; = \underbrace{ \begin{bmatrix} \vdots \\ {}^{A}\mathbf{N}_i {}^A\mathbf{p}_{C_i} \\ \vdots \end{bmatrix} }_{\mathbf{b}} \end{align*}" src="form_240.png"/>
</p>
<p>Since each pixel measurement provides two constraints, as long as <img class="formulaInl" alt="$m&gt;1$" src="form_241.png"/>, we will have enough constraints to triangulate the feature. In practice, the more views of the feature the better the triangulation and thus normally want to have a feature seen from at least five views. We could select two rows of the each <img class="formulaInl" alt="${}^{A}\mathbf{N}_i$" src="form_242.png"/> to reduce the number of rows, but by having a square system we can perform the following "trick". </p><p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \mathbf{A}^\top\mathbf{A}~ {}^A\mathbf{p}_f &amp;= \mathbf{A}^\top\mathbf{b} \\ \Big( \sum_i {}^{A}\mathbf{N}_i^\top {}^{A}\mathbf{N}_i \Big) {}^A\mathbf{p}_f &amp;= \Big( \sum_i {}^{A}\mathbf{N}_i^\top {}^{A}\mathbf{N}_i {}^A\mathbf{p}_{C_i} \Big) \end{align*}" src="form_243.png"/>
</p>
<p>This is a 3x3 system which can be quickly solved for as compared to the originl 3mx3m or 2mx2m system. We additionally check that the triangulated feature is "valid" and in front of the camera and not too far away. The <a href="https://en.wikipedia.org/wiki/Condition_number">condition number</a> of the above linear system and reject systems that are "sensitive" to errors and have a large value.</p>
<h1><a class="anchor" id="featinit-linear-1d"></a>
1D Depth Triangulation</h1>
<p>We wish to create a solvable linear system that can give us an initial guess for the 1D depth position of our feature. To do this, we take all the poses that the feature is seen from to be of known quantity along with the bearing in the anchor frame. This feature will be triangulated in some anchor camera frame <img class="formulaInl" alt="$\{A\}$" src="form_222.png"/> which we can arbitrary pick. We define it as its normalized image coordiantes <img class="formulaInl" alt="$[u_n ~ v_n ~ 1]^\top$" src="form_244.png"/> in tha anchor frame. If the feature <img class="formulaInl" alt="$\mathbf{p}_f$" src="form_223.png"/> is observed by pose <img class="formulaInl" alt="$1\ldots m$" src="form_224.png"/>, given the anchor pose <img class="formulaInl" alt="$A$" src="form_225.png"/>, we can have the following transformation from any camera pose <img class="formulaInl" alt="$C_i, i=1\ldots m$" src="form_226.png"/>:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{C_i}\mathbf{p}_{f} &amp; = {}^{C_i}_A\mathbf{R} \left( {}^A\mathbf{p}_f - {}^A\mathbf{p}_{C_i}\right) \\ {}^A\mathbf{p}_f &amp; = {}^{C_i}_A\mathbf{R}^\top {}^{C_i}\mathbf{p}_{f} + {}^A\mathbf{p}_{C_i} \\ {}^{A}z_{f} {}^A\mathbf{b}_f &amp; = {}^{C_i}_A\mathbf{R}^\top {}^{C_i}\mathbf{p}_{f} + {}^A\mathbf{p}_{C_i} \\ \end{align*}" src="form_245.png"/>
</p>
<p>In the absents of noise, the measurement in the current frame is the bearing <img class="formulaInl" alt="${}^{C_i}\mathbf{b}$" src="form_228.png"/> and its depth <img class="formulaInl" alt="${}^{C_i}z$" src="form_229.png"/>.</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{C_i}\mathbf{p}_f &amp; = {}^{C_i}z_{f} {}^{C_i}\mathbf{b}_{f} = {}^{C_i}z_{f} \begin{bmatrix} u_n \\ v_n \\ 1 \end{bmatrix} \end{align*}" src="form_230.png"/>
</p>
<p>We note that <img class="formulaInl" alt="$u_n$" src="form_231.png"/> and <img class="formulaInl" alt="$v_n$" src="form_232.png"/> represent the undistorted normalized image coordinates. This bearing can be warped into the the anchor frame by substituting into the above equation:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{A}z_{f} {}^A\mathbf{b}_f &amp; = {}^{C_i}_A\mathbf{R}^\top {}^{C_i}z_{f} {}^{C_i}\mathbf{b}_{f} + {}^A\mathbf{p}_{C_i} \\ &amp; = {}^{C_i}z_{f} {}^{A}\mathbf{b}_{C_i \rightarrow f} + {}^A\mathbf{p}_{C_i} \end{align*}" src="form_246.png"/>
</p>
<p>To remove the need to estimate the extra degree of freedom of depth <img class="formulaInl" alt="${}^{C_i}z_{f}$" src="form_234.png"/>, we define the following vectors which are orthoganal to the bearing <img class="formulaInl" alt="${}^{A}\mathbf{b}_{C_i \rightarrow f}$" src="form_235.png"/>:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{A}\mathbf{N}_i &amp;= \lfloor {}^{A}\mathbf{b}_{C_i \rightarrow f} \times\rfloor \end{align*}" src="form_247.png"/>
</p>
<p>All three rows are perpendicular to the vector <img class="formulaInl" alt="${}^{A}\mathbf{b}_{C_i \rightarrow f}$" src="form_235.png"/> and thus <img class="formulaInl" alt="${}^{A}\mathbf{N}_i{}^{A}\mathbf{b}_{C_i \rightarrow f}=\mathbf{0}_3$" src="form_237.png"/>. We can then multiple the transform equation/constraint to form two equation which only relates to the unknown <img class="formulaInl" alt="${}^{A}z_{f}$" src="form_248.png"/>:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} ({}^{A}\mathbf{N}_i {}^A\mathbf{b}_f) {}^{A}z_{f} &amp; = {}^{A}\mathbf{N}_i {}^{C_i}z_{f} {}^{A}\mathbf{b}_{C_i \rightarrow f} + {}^{A}\mathbf{N}_i {}^A\mathbf{p}_{C_i} \\ &amp; = {}^{A}\mathbf{N}_i {}^A\mathbf{p}_{C_i} \end{align*}" src="form_249.png"/>
</p>
<p>We can then formulate the following system:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \Big( \sum_i ({}^{A}\mathbf{N}_i{}^A\mathbf{b}_f)^\top ({}^{A}\mathbf{N}_i{}^A\mathbf{b}_f) \Big) {}^{A}z_{f} &amp;= \Big( \sum_i ({}^{A}\mathbf{N}_i{}^A\mathbf{b}_f)^\top {}^{A}\mathbf{N}_i{}^A \mathbf{b}_i \Big) \end{align*}" src="form_250.png"/>
</p>
<p>This is a 1x1 system which can be quickly solved for with a single scalar division. We additionally check that the triangulated feature is "valid" and in front of the camera and not too far away. The full feature can be reconstructed by <img class="formulaInl" alt="$ {}^A\mathbf{p}_f = {}^{A}z_{f} {}^A\mathbf{b}_f$" src="form_251.png"/>.</p>
<h1><a class="anchor" id="featinit-nonlinear"></a>
3D Inverse Non-linear Optimization</h1>
<p>After we get the triangulated feature 3D position, a nonlinear least-squares will be performed to refine this estimate. In order to achieve good numerical stability, we use the inverse depth representation for point feature which helps with convergence. We find that in most cases this problem converges within 2-3 iterations in indoor environments. The feature transformation can be written as:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} {}^{C_i}\mathbf{p}_f &amp; = {}^{C_i}_A\mathbf{R} \left( {}^A\mathbf{p}_f - {}^A\mathbf{p}_{C_i} \right) \\ &amp;= {}^Az_f {}^{C_i}_A\mathbf{R} \left( \begin{bmatrix} {}^Ax_f/{}^Az_f \\ {}^Ay_f/{}^Az_f \\ 1 \end{bmatrix} - \frac{1}{{}^Az_f} {}^A\mathbf{p}_{C_i} \right) \\ \Rightarrow \frac{1}{{}^Az_f} {}^{C_i}\mathbf{p}_f &amp; = {}^{C_i}_A\mathbf{R} \left( \begin{bmatrix} {}^Ax_f/{}^Az_f \\ {}^Ay_f/{}^Az_f \\ 1 \end{bmatrix} - \frac{1}{{}^Az_f} {}^A\mathbf{p}_{C_i} \right) \end{align*}" src="form_252.png"/>
</p>
<p>We define <img class="formulaInl" alt="$u_A = {}^Ax_f/{}^Az_f$" src="form_253.png"/>, <img class="formulaInl" alt="$v_A = {}^Ay_f/{}^Az_f$" src="form_254.png"/>, and <img class="formulaInl" alt="$\rho_A = {1}/{{}^Az_f}$" src="form_255.png"/> to get the following measurement equation:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} h(u_A, v_A, \rho_A) &amp; = {}^{C_i}_A\mathbf{R} \left( \begin{bmatrix} u_A \\ v_A \\ 1 \end{bmatrix} - \rho_A {}^A\mathbf{p}_{C_i} \right) \end{align*}" src="form_256.png"/>
</p>
<p>The feature measurement seen from the <img class="formulaInl" alt="$\{C_i\}$" src="form_257.png"/> camera frame can be reformulated as:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \mathbf{z} &amp; = \begin{bmatrix} u_i \\ v_i \end{bmatrix} \\ &amp;= \begin{bmatrix} h(u_A, v_A, \rho_A)(1) / h(u_A, v_A, \rho_A)(3) \\ h(u_A, v_A, \rho_A)(2) / h(u_A, v_A, \rho_A)(3) \\ \end{bmatrix} \\ &amp; = \mathbf{h}(u_A, v_A, \rho_A) \end{align*}" src="form_258.png"/>
</p>
<p>Therefore, we can have the least-squares formulated and Jacobians:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \operatorname*{argmin}_{u_A, v_A, \rho_A}||{\mathbf{z} - \mathbf{h}(u_A, v_A, \rho_A)}||^2 \end{align*}" src="form_259.png"/>
</p>
 <p class="formulaDsp">
<img class="formulaDsp" alt="\begin{align*} \frac{\partial \mathbf{h}(u_A, v_A, \rho_A)}{\partial {h}(u_A, v_A, \rho_A)} &amp; = \begin{bmatrix} 1/h(\cdots)(1) &amp; 0 &amp; -h(\cdots)(1)/h(\cdots)(3)^2 \\ 0 &amp; 1/h(\cdots)(2) &amp; -h(\cdots)(2)/h(\cdots)(3)^2 \end{bmatrix} \\ \frac{\partial {h}(u_A, v_A, \rho_A)}{\partial [u_A, v_A, \rho_A]} &amp; = {}^{C_i}_A\mathbf{R} \begin{bmatrix} \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 0 \end{bmatrix} &amp; -{}^A\mathbf{p}_{C_i} \end{bmatrix} \end{align*}" src="form_260.png"/>
</p>
<p>The least-squares problem can be solved with <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm">Gaussian-Newton</a> or <a href="https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm">Levenberg-Marquart</a> algorithm. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
制作者 &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
